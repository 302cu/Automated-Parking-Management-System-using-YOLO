{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1i-9Iv7cMNG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install super-gradients\n",
        "!pip install --upgrade pillow\n",
        "!pip install --upgrade torchvision\n",
        "!pip install super-gradients\n",
        "!pip install torch\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be7OxxZHcNUB",
        "outputId": "7586bcbf-3fbc-4be5-b390-570addc8b072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 06:55:10] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: boto3 required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: deprecated required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: coverage required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: sphinx-rtd-theme required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: torchmetrics required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: hydra-core required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: omegaconf required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxruntime required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnx required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: pillow==9.4.0 does not satisfy requirement pillow>=10.2.0\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: einops required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: treelib required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: stringcase required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: rapidfuzz required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: json-tricks required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxsim required but not found\u001b[0m\n",
            "[2024-05-30 06:55:17] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: data-gradients required but not found\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO, NAS\n",
        "import cv2\n",
        "import requests\n",
        "import json\n",
        "from ultralytics import models\n",
        "from super_gradients.training import Trainer, dataloaders, models\n",
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SYWbUx2cUZ1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPzlCyaqcZy0"
      },
      "outputs": [],
      "source": [
        "car_detection_model_path = '/content/drive/MyDrive/Colab Notebooks/Models/CarDetection.pt'\n",
        "parking_spot_detection_model_path = '/content/drive/MyDrive/Models/Colab Notebooks/SpotsDetection.pt'\n",
        "car_detection_4_plates_model_path = '/content/drive/MyDrive/Colab Notebooks/Models/bestcar.pt'\n",
        "plate_detection_model_path = '/content/drive/MyDrive/Colab Notebooks/Models/bestplate.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_T1JLZsfnLF"
      },
      "outputs": [],
      "source": [
        "car_detection_model = YOLO(car_detection_model_path)\n",
        "car_detection_4_plate_model = YOLO(car_detection_4_plates_model_path)\n",
        "plate_detection_model = YOLO(plate_detection_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtBkwyLtdgtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90a4c82-7fda-4e34-c6b9-2a2ef850b77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 06:57:00] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-05-30 06:57:00] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "Downloading: \"https://sghub.deci.ai/models/yolo_nas_l_coco.pth\" to /root/.cache/torch/hub/checkpoints/yolo_nas_l_coco.pth\n",
            "100%|██████████| 256M/256M [00:17<00:00, 15.5MB/s]\n",
            "[2024-05-30 06:57:20] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n"
          ]
        }
      ],
      "source": [
        "parking_spot_detection_model = models.get(model_name = 'yolo_nas_l', pretrained_weights = 'coco')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enzoJRcxjNMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd546ed-ddef-4a48-d695-e3f6d6ed32fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint file found: /content/drive/MyDrive/Colab Notebooks/checkpoints/race_number/RUN_20240523_220735_495739/ckpt_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 06:58:23] INFO - checkpoint_utils.py - Successfully loaded model weights from /content/drive/MyDrive/Colab Notebooks/checkpoints/race_number/RUN_20240523_220735_495739/ckpt_best.pth EMA checkpoint.\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/checkpoints/race_number/RUN_20240523_220735_495739/ckpt_best.pth\"\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"Checkpoint file not found: {checkpoint_path}\")\n",
        "else:\n",
        "    print(f\"Checkpoint file found: {checkpoint_path}\")\n",
        "\n",
        "    parking_spot_detection_model = models.get(model_name = 'yolo_nas_l',\n",
        "                            num_classes=1,\n",
        "                            checkpoint_path=checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWcuGkY_rGN9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, Colors\n",
        "\n",
        "def plot_bounding_boxes(yolo_result,image_choosen, colors=Colors()):\n",
        "    \"\"\"Draw bounding boxes from yolo.predict() result\"\"\"\n",
        "    # image_choosen = '1'\n",
        "    image = yolo_result.orig_img[..., ::-1]\n",
        "    annotate = Annotator(np.ascontiguousarray(image))\n",
        "    classes = yolo_result.boxes.cls.tolist()\n",
        "    scores = yolo_result.boxes.conf.tolist()\n",
        "    boxes = yolo_result.boxes.xyxy\n",
        "    image = cv2.imread(image_path)\n",
        "    width, height = image.shape[1], image.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "    for box, class_, score in zip(boxes, classes, scores):\n",
        "        color = np.random.randint(0, 255, 3).tolist()\n",
        "        tag = f\"{yolo_result.names[class_].title()}: {score:.0%}\"\n",
        "        annotate.box_label(box, tag, color)\n",
        "\n",
        "\n",
        "\n",
        "    return Image.fromarray(annotate.result())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_chars(num_list):\n",
        "    char_map = {\n",
        "        '00': '0',\n",
        "        '01': '1',\n",
        "        '05': '2',\n",
        "        '07': '3',\n",
        "        '03': '4',\n",
        "        '02': '5',\n",
        "        '06': '6',\n",
        "        '04': '7',\n",
        "        '08': '8',\n",
        "        '10': '9',\n",
        "        '22': 'ا',\n",
        "        '11': 'ب',\n",
        "        '24': 'ح',\n",
        "        '28': 'د',\n",
        "        '20': 'ر',\n",
        "        '12': 'س',\n",
        "        '25': 'ص',\n",
        "        '21': 'ط',\n",
        "        '26': 'ع',\n",
        "        '10': 'ق',\n",
        "        '17': 'ك',\n",
        "        '18': 'ل',\n",
        "        '13': 'م',\n",
        "        '19': 'ن',\n",
        "        '14': 'ه',\n",
        "        '23': 'و',\n",
        "        '16': 'ي'\n",
        "    }\n",
        "\n",
        "    converted_chars = []\n",
        "    for num_str in num_list:\n",
        "        if num_str in char_map:\n",
        "            converted_chars.append(char_map[num_str])\n",
        "        else:\n",
        "            converted_chars.append('X')\n",
        "\n",
        "    # Sort the converted_chars list\n",
        "    converted_chars.sort()\n",
        "    return converted_chars"
      ],
      "metadata": {
        "id": "JuXERpZ7JGcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def platesProcess(image):\n",
        "    dh, dw, _ = image.shape\n",
        "    conf = 0.3\n",
        "\n",
        "    result = car_detection_4_plate_model(image, conf=conf, verbose=False)[0]\n",
        "    highest_conf_index = 0\n",
        "    highest_conf = 0\n",
        "\n",
        "    bounding_boxes = plot_bounding_boxes_car(result)\n",
        "    if bounding_boxes:\n",
        "        for i, box in enumerate(bounding_boxes):\n",
        "            if len(box) == 5:\n",
        "                class_, x, y, w, h = box\n",
        "                if class_ > highest_conf:\n",
        "                    highest_conf = class_\n",
        "                    highest_conf_index = i\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            x, y, w, h = bounding_boxes[highest_conf_index]\n",
        "            x = int((x - w / 2) * dw)\n",
        "            y = int((y - h / 2) * dh)\n",
        "            w = int(w * dw)\n",
        "            h = int(h * dh)\n",
        "\n",
        "            imgCrop = image[y:y+h, x:x+w]\n",
        "            plates_nums = PredictPlate(imgCrop)\n",
        "\n",
        "            return image, convert_to_chars(plates_nums)\n",
        "        except IndexError:\n",
        "            print(\"Error: No valid bounding box found.\")\n",
        "            return image, []\n",
        "    else:\n",
        "        print(\"Error: No bounding boxes returned.\")\n",
        "        return image, []"
      ],
      "metadata": {
        "id": "kDQO_MTUH28R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqKH3kdUPSRA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics.utils.plotting import Annotator, Colors\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bounding_boxes_plate(yolo_result):\n",
        "    \"\"\"Draw bounding boxes from yolo.predict() result\"\"\"\n",
        "    classes = []\n",
        "    if yolo_result.boxes:\n",
        "        for class_ in yolo_result.boxes.cls.tolist():\n",
        "            classes.append(yolo_result.names[class_])\n",
        "    return classes"
      ],
      "metadata": {
        "id": "KyLh5NlFM77e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PredictPlate(image):\n",
        "    conf= 0.3\n",
        "\n",
        "\n",
        "    result = plate_detection_model(image, conf=conf, verbose=False)[0]\n",
        "    platePredictions = plot_bounding_boxes_plate(result)\n",
        "\n",
        "    return platePredictions"
      ],
      "metadata": {
        "id": "FHqr3-GYK3BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vaa1ymyxPLHX"
      },
      "outputs": [],
      "source": [
        "def PredictParking(image):\n",
        "    conf = 0.60\n",
        "    predictions = parking_spot_detection_model.predict(image, conf=conf)\n",
        "    bboxes = predictions.prediction.bboxes_xyxy\n",
        "    count = len(bboxes)\n",
        "    width, height = image.shape[1], image.shape[0]\n",
        "    parking_bboxes = []\n",
        "    for bbox in predictions.prediction.bboxes_xyxy:\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        x1 = x1 / width\n",
        "        y1 = y1 / height\n",
        "        x2 = x2 / width\n",
        "        y2 = y2 / height\n",
        "        parking_bboxes.append([ x1, y1, x2, y2])\n",
        "\n",
        "    return  parking_bboxes, count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bounding_boxes_car(yolo_result, colors=Colors()):\n",
        "    \"\"\"Draw bounding boxes from yolo.predict() result\"\"\"\n",
        "    boxes =[]\n",
        "    for x, y, w, h in yolo_result.boxes.xywhn.tolist():\n",
        "        boxes.append([x, y, w, h])\n",
        "\n",
        "    return boxes\n"
      ],
      "metadata": {
        "id": "xnZDQlZiRL-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMchw5qfP6Jm"
      },
      "outputs": [],
      "source": [
        "def PredictCars(image):\n",
        "    conf= 0.3\n",
        "    car_detection_model = YOLO(car_detection_model_path)\n",
        "    result = car_detection_model(image)[0]\n",
        "    Carspredictions = plot_bounding_boxes_car(result)\n",
        "    return Carspredictions, len(Carspredictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fen-hDEAbAWH"
      },
      "outputs": [],
      "source": [
        "video_path = '/content/drive/MyDrive/Colab Notebooks/Colab Notebooks/Data/boxes/Screenshot 2024-05-29 102057.png'\n",
        "image = cv2.imread(video_path)\n",
        "\n",
        "fr, pa = await platesProcess(image)\n",
        "pa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE7RWV1xsjUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfe79cf-924c-495b-cc48-27acd22d5049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting websockets\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/130.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets\n",
            "Successfully installed websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install websockets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "sKW6yI9Chp5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2d0e9b-9e1d-4b5b-8637-ded9cecfc2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes(image, parking_bboxes, car_bboxes,iou_sum_matrix):\n",
        "    # image_path = \"/content/drive/MyDrive/Colab Notebooks/Colab Notebooks/Data/datasets/train/images/10.png\"\n",
        "    # image = cv2.imread(image_path)\n",
        "    # x1, y1, x2, y2\n",
        "    # count of free parking and count of incorrectly prak\n",
        "    count_free_park =0\n",
        "    count_incorrectly_prak = 0\n",
        "    for i, park in enumerate(iou_sum_matrix):\n",
        "        if park <= 0.05:\n",
        "            count_free_park= count_free_park +1\n",
        "            # print('The number of free parking is : ', count_free_park)\n",
        "        elif park >0.05 and park <=0.5:\n",
        "            count_incorrectly_prak = count_incorrectly_prak +1\n",
        "\n",
        "    print('The number of free parking is : ', count_free_park)\n",
        "    print('The number of incorrectly parking is : ', count_incorrectly_prak)\n",
        "    fre_p = count_free_park\n",
        "    incor_p = count_incorrectly_prak\n",
        "\n",
        "\n",
        "\n",
        "    parkingbboxes = []\n",
        "    for parking_count,pbox in enumerate(parking_bboxes,1):\n",
        "        start_point = (int(pbox[0] * image.shape[1]), int(pbox[1] * image.shape[0]))\n",
        "        end_point = (int(pbox[2] * image.shape[1]), int(pbox[3] * image.shape[0]))\n",
        "        count_free_park =0\n",
        "        # for i, park in enumerate(iou_sum_matrix):\n",
        "        if iou_sum_matrix[parking_count-1] <= 0.05:\n",
        "            cv2.rectangle(image, start_point, end_point, (0, 255, 0), 2)\n",
        "            cv2.putText(image, f\"Parking {parking_count}\", (int(pbox[0] * image.shape[1]), int(pbox[1] * image.shape[0]-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "            count_free_park= count_free_park +1\n",
        "        elif iou_sum_matrix[parking_count-1] >0.05 and iou_sum_matrix[parking_count-1] <=0.5:\n",
        "            cv2.rectangle(image, start_point, end_point, (0, 0, 255), 2)\n",
        "            cv2.putText(image, f\"Parking {parking_count}\", (int(pbox[0] * image.shape[1]), int(pbox[1] * image.shape[0]-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        else:\n",
        "            cv2.rectangle(image, start_point, end_point, (0, 165, 255), 2)\n",
        "            cv2.putText(image, f\"Parking {parking_count}\", (int(pbox[0] * image.shape[1]), int(pbox[1] * image.shape[0]-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 2)\n",
        "\n",
        "\n",
        "    carbboxes =[]\n",
        "    for values in car_bboxes:\n",
        "        xc = float(values[0])\n",
        "        yc = float(values[1])\n",
        "        w = float(values[2])\n",
        "        h = float(values[3])\n",
        "        carbboxes.append([xc, yc, w, h])\n",
        "\n",
        "    for car_count, cbbox in enumerate(carbboxes, 1):\n",
        "        xc = int(cbbox[0] * image.shape[1])\n",
        "        yc = int(cbbox[1] * image.shape[0])\n",
        "        w = int(cbbox[2] * image.shape[1])\n",
        "        h = int(cbbox[3] * image.shape[0])\n",
        "        cv2.rectangle(image, (xc - w // 2, yc - h // 2), (xc + w // 2, yc + h // 2), (255, 0, 0), 2)\n",
        "        # cv2.putText(image, f\"Car {car_count}\", (xc - w // 2, yc - h // 2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    img=image\n",
        "\n",
        "\n",
        "    return img, fre_p, incor_p"
      ],
      "metadata": {
        "id": "ml26pJKPBTEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    (x1, y1, x2, y2), (x, y, w, h) = box1[-4:], box2[-4:]\n",
        "    # box1 = [x1 * image.shape[1], y1  * image.shape[0], x2 * image.shape[1], y2  * image.shape[0]]\n",
        "    box2 = [x - w / 2, y - h / 2, w, h]\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    x_intersection = max(box1[0], box2[0])\n",
        "    y_intersection = max(box1[1], box2[1])\n",
        "    #                        x_max ,  x_max =x+w\n",
        "    x_overlap = max(0, min( box1[2], box2[0] + box2[2]) - x_intersection)\n",
        "    #                      y_max  , y_max= y+h\n",
        "    y_overlap = max(0, min(box1[3], box2[1] + box2[3]) - y_intersection)\n",
        "\n",
        "    # Calculate areas\n",
        "    intersection_area = x_overlap * y_overlap\n",
        "    #           ( x_max - x_min  ) * (y_max - y_min)\n",
        "    box1_area = ((box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
        "      #               w*h\n",
        "    box2_area = box2[2] * box2[3]\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# Function to calculate IoU between all pairs of bounding boxes\n",
        "def calculate_iou_matrix(boxes1, boxes2):\n",
        "    iou_matrix = []\n",
        "    for box1 in boxes1:\n",
        "        iou_row = []\n",
        "        for box2 in boxes2:\n",
        "            iou_row.append(calculate_iou(box1, box2))\n",
        "        iou_matrix.append(iou_row)\n",
        "    return iou_matrix\n",
        "# def sum_matrix_iou(image):\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "moU0BsMAeSMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "async def makeAnnotation(frame):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        car_boxes_future = executor.submit(PredictCars, frame)\n",
        "        parking_boxes_future = executor.submit(PredictParking, frame)\n",
        "\n",
        "        car_boxes, car_count = car_boxes_future.result()\n",
        "        parking_boxes, parking_count = parking_boxes_future.result()\n",
        "        iou_matrix = calculate_iou_matrix(parking_boxes, car_boxes)\n",
        "\n",
        "    # Print IoU matrix\n",
        "    iou_sum_matrix =[]\n",
        "    park_number = []\n",
        "    for i, row in enumerate(iou_matrix):\n",
        "        # print(f\"IoU scores for box {i+1} in parking:\")\n",
        "        iou_sum = 0.0\n",
        "        for j, iou_score in enumerate(row):\n",
        "            # print(f\"  With box {j+1} in car: {iou_score}\")\n",
        "            iou_sum= iou_sum + float(iou_score)\n",
        "        iou_sum_matrix.append(iou_sum)\n",
        "        park_number.append(i+1)\n",
        "        # print(f\"IoU sum {iou_sum_matrix[i]} in parking:\")\n",
        "\n",
        "    image_bb, free, wrong = draw_bounding_boxes(frame, parking_boxes, car_boxes,iou_sum_matrix)\n",
        "#    Newframe = draw_bounding_boxes(frame, parking_boxes, car_boxes)\n",
        "    return image_bb, car_count, parking_count, free, wrong\n"
      ],
      "metadata": {
        "id": "IveckRMwALN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port = 8548"
      ],
      "metadata": {
        "id": "mqgmP631JrtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "port = port+1\n",
        "conf.get_default().auth_token = 'USE THE AUTH TOKEN FROM NGROK' # IMPORTANT NOTE\n",
        "print('Your app is running here:', ngrok.connect(port).public_url)"
      ],
      "metadata": {
        "id": "OOykYzL5hzHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc7fdef-1e8c-4c9e-fa7d-71bfb943995a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 08:58:58] INFO - ngrok.py - Opening tunnel named: http-8558-27f2a528-4858-4a54-815a-be4ddcc105a4\n",
            "[2024-05-30 08:58:58] INFO - process.py - Overriding default auth token\n",
            "[2024-05-30 08:58:58] INFO - process.py - t=2024-05-30T08:58:58+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "[2024-05-30 08:58:58] INFO - process.py - t=2024-05-30T08:58:58+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "[2024-05-30 08:58:58] INFO - process.py - t=2024-05-30T08:58:58+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "[2024-05-30 08:58:58] INFO - process.py - t=2024-05-30T08:58:58+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=start pg=/api/tunnels id=9c2ff8eec975ca50\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=end pg=/api/tunnels id=9c2ff8eec975ca50 status=200 dur=206.425µs\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=start pg=/api/tunnels id=d7b2c44577ec4587\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=end pg=/api/tunnels id=d7b2c44577ec4587 status=200 dur=71.075µs\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=start pg=/api/tunnels id=e67cfe6693dfbd4d\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8558-27f2a528-4858-4a54-815a-be4ddcc105a4 addr=http://localhost:8558 url=https://7200-104-199-140-71.ngrok-free.app\n",
            "[2024-05-30 08:58:59] INFO - process.py - t=2024-05-30T08:58:59+0000 lvl=info msg=end pg=/api/tunnels id=e67cfe6693dfbd4d status=201 dur=196.381861ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st2AITDSsov6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dab3c5-ef26-4bac-81d0-bf83ec2c7678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 08:59:00] INFO - server.py - server listening on 127.0.0.1:8558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:00:12] INFO - process.py - t=2024-05-30T09:00:12+0000 lvl=info msg=\"join connections\" obj=join id=b7b8c519e2c3 l=127.0.0.1:8558 r=37.224.52.18:54030\n",
            "[2024-05-30 09:00:12] INFO - server.py - connection rejected (426 Upgrade Required)\n",
            "[2024-05-30 09:00:12] INFO - server.py - connection closed\n",
            "[2024-05-30 09:00:12] INFO - process.py - t=2024-05-30T09:00:12+0000 lvl=info msg=\"join connections\" obj=join id=bba36b3f69c3 l=127.0.0.1:8558 r=37.224.52.18:54030\n",
            "[2024-05-30 09:00:12] INFO - server.py - connection rejected (426 Upgrade Required)\n",
            "[2024-05-30 09:00:12] INFO - server.py - connection closed\n",
            "[2024-05-30 09:01:12] INFO - process.py - t=2024-05-30T09:01:12+0000 lvl=info msg=\"join connections\" obj=join id=a62687a91333 l=127.0.0.1:8558 r=37.224.52.18:60635\n",
            "[2024-05-30 09:01:12] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Error: No bounding boxes returned.\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Error: No bounding boxes returned.\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:03:00] INFO - server.py - connection closed\n",
            "[2024-05-30 09:08:30] INFO - process.py - t=2024-05-30T09:08:30+0000 lvl=info msg=\"join connections\" obj=join id=da67a60a4862 l=127.0.0.1:8558 r=37.224.52.18:33834\n",
            "[2024-05-30 09:08:30] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:09:28] INFO - server.py - connection closed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:09:42] INFO - process.py - t=2024-05-30T09:09:42+0000 lvl=info msg=\"join connections\" obj=join id=e82ee4475d01 l=127.0.0.1:8558 r=37.224.52.18:35273\n",
            "[2024-05-30 09:09:42] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:09:54] INFO - server.py - connection closed\n",
            "[2024-05-30 09:11:09] INFO - process.py - t=2024-05-30T09:11:09+0000 lvl=info msg=\"join connections\" obj=join id=2bd7c3b22c96 l=127.0.0.1:8558 r=37.224.52.18:52815\n",
            "[2024-05-30 09:11:09] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:11:28] INFO - server.py - connection closed\n",
            "[2024-05-30 09:12:25] INFO - process.py - t=2024-05-30T09:12:25+0000 lvl=info msg=\"join connections\" obj=join id=57c95d2936ad l=127.0.0.1:8558 r=37.224.52.18:38945\n",
            "[2024-05-30 09:12:25] INFO - server.py - connection open\n",
            "[2024-05-30 09:12:26] INFO - server.py - connection closed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Client disconnected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:12:46] INFO - process.py - t=2024-05-30T09:12:46+0000 lvl=info msg=\"join connections\" obj=join id=f5fb89d9cef2 l=127.0.0.1:8558 r=37.224.52.18:29430\n",
            "[2024-05-30 09:12:46] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Error: No bounding boxes returned.\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Error: No bounding boxes returned.\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:14:14] INFO - server.py - connection closed\n",
            "[2024-05-30 09:15:32] INFO - process.py - t=2024-05-30T09:15:32+0000 lvl=info msg=\"join connections\" obj=join id=a715d7cce4c8 l=127.0.0.1:8558 r=37.224.52.18:28304\n",
            "[2024-05-30 09:15:32] INFO - server.py - connection open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client connected\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n",
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-05-30 09:15:45] INFO - server.py - connection closed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame received\n",
            "got video 2\n",
            "Frame processed and sent\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import base64\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import websockets\n",
        "import nest_asyncio\n",
        "from websockets.exceptions import ConnectionClosedError\n",
        "\n",
        "\n",
        "\n",
        "async def process_video(websocket, path):\n",
        "    print(\"Client connected\")\n",
        "    try:\n",
        "        async for message in websocket:\n",
        "            print(\"Frame received\")\n",
        "            message_data = json.loads(message)\n",
        "            image_data = message_data.get('imageData')\n",
        "            video_number = message_data.get('videoNumber')\n",
        "\n",
        "            if not image_data:\n",
        "                continue\n",
        "\n",
        "            image_bytes = image_data.split('data:image/jpeg;base64,')[1]\n",
        "            image_np = np.frombuffer(base64.b64decode(image_bytes), dtype=np.uint8)\n",
        "            frame = cv2.imdecode(image_np, cv2.IMREAD_COLOR)\n",
        "\n",
        "            if video_number == 1:\n",
        "                frame, car_count,  parking_count, free, wrong = await makeAnnotation(frame)\n",
        "                annotations = {\n",
        "                    'car count': car_count,\n",
        "                    'parking count': parking_count,\n",
        "                    'free parking': free,\n",
        "                    'wrong parking': wrong,\n",
        "                    'frame': f'data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", frame)[1]).decode(\"utf-8\")}',\n",
        "                    'videoNumber': video_number\n",
        "                }\n",
        "            elif video_number == 2:\n",
        "                print(\"got video 2\")\n",
        "                frame, platesNums = await platesProcess(frame)\n",
        "                annotations = {\n",
        "                    'plates Nums': platesNums,\n",
        "                    'frame': f'data:image/jpeg;base64,{base64.b64encode(cv2.imencode(\".jpg\", frame)[1]).decode(\"utf-8\")}',\n",
        "                    'videoNumber': video_number\n",
        "                }\n",
        "\n",
        "            await websocket.send(json.dumps(annotations))\n",
        "            print(\"Frame processed and sent\")\n",
        "    except ConnectionClosedError:\n",
        "        print(\"Client disconnected\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing frame: {e}\")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "start_server = websockets.serve(process_video, '127.0.0.1', port)\n",
        "\n",
        "print(\"Server started\")\n",
        "asyncio.get_event_loop().run_until_complete(start_server)\n",
        "asyncio.get_event_loop().run_forever()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}